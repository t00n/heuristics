\documentclass[a4paper,12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{float}
\usepackage{url}

\author{Antoine CARPENTIER}
\title{Heuristic optimization\\ \small Implementation exercises 1}

\bibliographystyle{apalike}

\begin{document}
\maketitle

\section{Exercise 1}

\subsection{Implementation}

The code is built modularly. The \texttt{construction\_search} function accepts pointers to function that modifies its behavior : 

\begin{itemize}
    \item A function \texttt{pick\_elem} that picks a non covered element
    \item A function \texttt{pick\_subset} that picks a non used subset containing the previous element. Because only non used subsets are picked, no redundant subset is added during the construction
    \item A function \texttt{cost\_function} that computes the cost of a subset
\end{itemize}

To build the algorithms CH1 to CH4, the \texttt{construction\_search} function is parametrized as such : 

\begin{itemize}
    \item CH1 : with \texttt{random\_pick\_element}, \texttt{random\_pick\_subset} and \texttt{static\_cost} (unused)
    \item CH2 : with \texttt{random\_pick\_element}, \texttt{greedy\_pick\_subset} and \texttt{static\_cost}
    \item CH3 : with \texttt{random\_pick\_element}, \texttt{greedy\_pick\_subset} and \texttt{static\_cover\_cost}
    \item CH4 : with \texttt{random\_pick\_element}, \texttt{greedy\_pick\_subset} and \texttt{adaptive\_cover\_cost}
\end{itemize}

The function \texttt{random\_pick\_element} picks randomly a non covered element and is used everywhere.

The function \texttt{random\_pick\_subset} picks randomly an unused subset that contains the element.

The function \texttt{greedy\_pick\_subset} picks a unused subset with minimal that contains the element using the \texttt{cost\_function}.

The function \texttt{static\_cost} returns the raw cost of the subset.

The function \texttt{static\_cover\_cost} returns the raw cost of the subset divided by the number of elements in the subset.

The function \texttt{adaptive\_cover\_cost} returns the raw cost of the subset divided by the number of elements that it would add to the solution.

The function \texttt{eliminate\_redundancy} uses the function \texttt{find\_redundant\_subsets} to get every redundant subset and remove the set with highest cost (using \texttt{static\_cost})

\subsection{Results}

IPython and SciPy were used to process the results from the algorithms. You can find the \textit{ipynb} file in the archive.

\subsubsection{Total computation times}

\begin{itemize}
    \item CH1 : 1.3123996257781982 seconds
    \item CH2 : 1.0234956741333008 seconds
    \item CH3 : 1.0669968128204346 seconds
    \item CH4 : 1.0484178066253662 seconds
    \item CH1 + RE : 3.1139917373657227 seconds
    \item CH2 + RE : 1.7006745338439941 seconds
    \item CH3 + RE : 1.4156222343444824 seconds
    \item CH4 + RE : 1.1701548099517822 seconds
\end{itemize}

\subsubsection{Average percentage deviation from best known solutions}

\begin{itemize}
    \item CH1 : 35.29621653608673 \%
    \item CH2 : 0.27405351611183165 \%
    \item CH3 : 0.3016417317840776 \%
    \item CH4 : 0.1767634379498829 \%
    \item CH1 + RE : 27.81905654265422 \%
    \item CH2 + RE : 0.11592208166847057 \%
    \item CH3 + RE : 0.14073851429349368 \%
    \item CH4 + RE : 0.13197283301819474 \%
\end{itemize}

\subsubsection{Improvement of redundancy elimination}

0.9798387096774194 \% of instances are improved by the redundancy elimination.

mean : 0.147971704158
standard deviation 0.10057283968
max 0.470588235294
min 0.0

We use a Wilcoxon signed-rank test because we can not assume that the population is normally distributed. We use the \texttt{scipy.stats.wilcoxon} function from \cite{scipywilcoxon} with a confidence interval of 95\% and the null hypothesis that the benchmarks of the algorithms with and without redundancy elimination have the same mean.
The result is a pvalue of 1.2814523415056763e-41 which means that we reject the null hypothesis and conclude that redundancy elimination has a significant influence on the performance of the benchmarks.

\section{Exercise 2}

\subsection{Implementation}

The \texttt{perturbative\_search} function is parametrized by the type of improvement (first or best) and a \texttt{cost\_function}. It finds a local neighbour that improves the total cost using the \texttt{find\_improvement} function until it is stuck in a local minimum.
The \texttt{find\_improvement} function browse every neighbour to find the first or best improvement using the following technique. First it removes a subset randomly. Second it completes the partial cover using a greedy static cover cost construction.

\subsection{Results}

\subsubsection{Total computation times}

\begin{itemize}
    \item CH1 + FI : 3.607801914215088 seconds
    \item CH4 + FI : 1.5206809043884277 seconds
    \item CH1 + RE + FI : 3.5874764919281006 seconds
    \item CH4 + RE + FI : 1.3393275737762451 seconds
    \item CH1 + BI : 3.941063642501831 seconds
    \item CH4 + BI : 1.5877315998077393 seconds
    \item CH1 + RE + BI : 3.6423726081848145 seconds
    \item CH4 + RE + BI : 1.6437082290649414 seconds
\end{itemize}

\subsubsection{Average percentage deviation from best known solutions}

\begin{itemize}
    \item CH1 + FI : 26.474933439065072 \%
    \item CH4 + FI : 27.53480266030842 \%
    \item CH1 + RE + FI : 0.13006999602368838 \%
    \item CH4 + RE + FI : 0.12505620494919842 \%
    \item CH1 + BI : 0.3316475551888148 \%
    \item CH4 + BI : 26.957711390139718 \%
    \item CH1 + RE + BI : 0.08707997163917548 \%
    \item CH4 + RE + BI : 0.09924646850675854 \%
\end{itemize}

\subsubsection{Improvement of first improvement perturbative search}

Fraction of instances improved due to first improvement :  0.6451612903225806
mean : 0.091904539658
standard deviation : 0.13249853207
max : 0.715223097113
min : 0.0
The pvalue of 5.1681488905994952e-28 which means that we reject the null hypothesis and conclude that redundancy elimination has a significant influence on the performance of the benchmarks.

\subsubsection{Improvement of best improvement perturbative search}

Fraction of instances improved :  0.7258064516129032
mean : 7.56904281965
standard deviation : 16.5287532326
max : 73.4262295082
min : -0.117647058824
The pvalue of 1.0266751909277341e-31 which means that we reject the null hypothesis and conclude that redundancy elimination has a significant influence on the performance of the benchmarks.

\subsubsection{Comparison between first and best improvement}
Fraction of instances improved :  0.6774193548387096
mean : 5.66356672141
standard deviation : 12.2925930918
max : 57.0
min : -0.117647058824
The pvalue of 6.0141840973467213e-30 which means that we reject the null hypothesis and conclude that redundancy elimination has a significant influence on the performance of the benchmarks.

\bibliography{main}
\end{document}
